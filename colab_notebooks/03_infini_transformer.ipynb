{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Train InfiniTransformer"]},{"cell_type":"markdown","metadata":{},"source":["### Install Libs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install datasets\n","!pip install transformers -U\n","!pip install tiktoken"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2472,"status":"ok","timestamp":1719373618704,"user":{"displayName":"Matheus Rodrigues","userId":"10209371041900019376"},"user_tz":180},"id":"d1v601EhTRqt","outputId":"0c266feb-e17b-4da4-f6e4-9b6bbc76d7b7"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      3\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}],"source":["from google.colab import drive\n","\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1719373618704,"user":{"displayName":"Matheus Rodrigues","userId":"10209371041900019376"},"user_tz":180},"id":"FeLc1mFnTf3e","outputId":"480fa3c2-ff30-4d16-c4a2-35d4359da007"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/nlp_unicamp/final_project/Infini-attention-Transformer\n"]}],"source":["# Select the colab_notebooks folder of project\n","# %cd \"/content/drive/MyDrive/final_project/Infini-attention-Transformer\"\n","%cd \"/content/drive/MyDrive/Colab Notebooks/nlp_unicamp/final_project/Infini-attention-Transformer\""]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1719373618704,"user":{"displayName":"Matheus Rodrigues","userId":"10209371041900019376"},"user_tz":180},"id":"74v7SEBBTXyW"},"outputs":[],"source":["# !pip install datasets\n","# # !pip install accelerate -U\n","# !pip install transformers -U\n","# !pip install tiktoken"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import sys\n","\n","sys.path.append(\"../\")"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2583,"status":"ok","timestamp":1719373621286,"user":{"displayName":"Matheus Rodrigues","userId":"10209371041900019376"},"user_tz":180},"id":"1IWJ4jMwRz9q"},"outputs":[],"source":["import os\n","import requests\n","import math\n","import tiktoken\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from infini_attention_transformer.transformer_language_model import (\n","    TransformerLanguageModel,\n",")\n","from datasets import load_dataset, load_from_disk"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1719373621286,"user":{"displayName":"Matheus Rodrigues","userId":"10209371041900019376"},"user_tz":180},"id":"x5jEMDpsRz9r"},"outputs":[],"source":["# Hyperparameters\n","batch_size = 16  # How many batches per training step\n","context_length = 1024  # Length of the token chunk each batch\n","dim_input = 128  # The size of our model token embeddings\n","num_blocks = 4  # Number of transformer blocks\n","num_heads = 4  # Number of heads in Multi-head attention\n","learning_rate = 1e-4  # 0.001\n","dropout = 0.1  # Dropout rate\n","device = \"cuda\"  # Use Mac GPU if it's available.\n","\n","infni = True\n","segment_len = 64\n","\n","TORCH_SEED = 1337\n","\n","# torch.set_default_device(device)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1719373621286,"user":{"displayName":"Matheus Rodrigues","userId":"10209371041900019376"},"user_tz":180},"id":"SZfC-3-qRz9t"},"outputs":[],"source":["train_dataset = load_from_disk(\"data/\")\n","train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"labels\"])"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1719373621286,"user":{"displayName":"Matheus Rodrigues","userId":"10209371041900019376"},"user_tz":180},"id":"Iu9YleS1oauD","outputId":"4875eb37-3aeb-4e1c-87b7-6c63ee6416aa"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'labels'],\n","    num_rows: 99039\n","})"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1719373621286,"user":{"displayName":"Matheus Rodrigues","userId":"10209371041900019376"},"user_tz":180},"id":"qCy6liOdolsj"},"outputs":[],"source":["# verify if all batchs has same shape\n","# print(set(list(map(lambda i: (i['input_ids'].shape, i['labels'].shape), train_dataset))))"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1719373621286,"user":{"displayName":"Matheus Rodrigues","userId":"10209371041900019376"},"user_tz":180},"id":"jT6ulpQ0GDl8"},"outputs":[],"source":["# get 10% of train_dataset\n","# train_dataset = train_dataset.train_test_split(test_size=0.1)\n","# train_dataset = train_dataset[\"test\"]"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":447,"status":"ok","timestamp":1719373621731,"user":{"displayName":"Matheus Rodrigues","userId":"10209371041900019376"},"user_tz":180},"id":"nd8OpVzzRz9u"},"outputs":[],"source":["# encoding = tiktoken.get_encoding(\"cl100k_base\")\n","# tokenized_text = encoding.encode(text)\n","# # tokenized_text = torch.load(\"corpus.pt\")\n","# max_token_value = max(tokenized_text) + 1  # the maximum value of the tokenized numbers\n","# tokenized_text = torch.tensor(\n","#     tokenized_text, dtype=torch.long, device = device\n","# )\n","\n","encoding = tiktoken.get_encoding(\"cl100k_base\")\n","max_token_value = encoding.n_vocab + 1  #"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1719373621731,"user":{"displayName":"Matheus Rodrigues","userId":"10209371041900019376"},"user_tz":180},"id":"H5r_2JZXRz9v"},"outputs":[],"source":["# Split train and validation\n","# split_idx = int(len(tokenized_text) * 0.8)\n","# split_val_text = int(len(tokenized_text) * 0.9)\n","# print(split_val_text)\n","# train_data = tokenized_text[:split_idx]\n","# val_data = tokenized_text[split_idx:split_val_text]\n","# test_data = tokenized_text[split_val_text:]\n","\n","\n","from torch.utils.data import DataLoader\n","\n","# 80% for training and 10% for validation\n","train_dataset = train_dataset.train_test_split(test_size=0.2)\n","val_dataset = train_dataset[\"test\"]\n","train_dataset = train_dataset[\"train\"]\n","\n","# split 10% for test\n","val_dataset = val_dataset.train_test_split(test_size=0.5)\n","test_dataset = val_dataset[\"test\"]\n","val_dataset = val_dataset[\"train\"]\n","\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1719373621731,"user":{"displayName":"Matheus Rodrigues","userId":"10209371041900019376"},"user_tz":180},"id":"7ltNgySIGIpr","outputId":"ecc0ff25-1c0b-434b-e560-51b585976820"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset({\n","    features: ['input_ids', 'labels'],\n","    num_rows: 79231\n","})\n","Dataset({\n","    features: ['input_ids', 'labels'],\n","    num_rows: 9904\n","})\n","Dataset({\n","    features: ['input_ids', 'labels'],\n","    num_rows: 9904\n","})\n"]}],"source":["print(train_dataset)\n","print(val_dataset)\n","print(test_dataset)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1719373621731,"user":{"displayName":"Matheus Rodrigues","userId":"10209371041900019376"},"user_tz":180},"id":"KsM9eM0TJkDl","outputId":"2066a310-589d-4b79-8e0a-2ee398a1f395"},"outputs":[{"data":{"text/plain":["torch.Size([16, 1024])"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["next(iter(test_loader))[\"input_ids\"].shape"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":606,"status":"ok","timestamp":1719373622336,"user":{"displayName":"Matheus Rodrigues","userId":"10209371041900019376"},"user_tz":180},"id":"eGPp4HS1Rz9v","outputId":"902e0c64-8dc2-4b13-c1e2-841a23a8c3e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["TransformerLanguageModel(\n","  (token_embedding_lookup_table): Embedding(100279, 128)\n","  (transformer_blocks): Sequential(\n","    (0): TransformerBlock(\n","      (multi_head_attention_layer): InfiniMultiHeadAttention(\n","        (proj_k): Linear(in_features=128, out_features=128, bias=False)\n","        (proj_v): Linear(in_features=128, out_features=128, bias=False)\n","        (proj_q): Linear(in_features=128, out_features=128, bias=False)\n","        (proj_out): Linear(in_features=128, out_features=128, bias=False)\n","        (dropout_layer): Dropout(p=0.1, inplace=False)\n","      )\n","      (feed_forward_layer): FeedForward(\n","        (ffn): Sequential(\n","          (0): Linear(in_features=128, out_features=512, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=512, out_features=128, bias=True)\n","          (3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","      (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (1): TransformerBlock(\n","      (multi_head_attention_layer): InfiniMultiHeadAttention(\n","        (proj_k): Linear(in_features=128, out_features=128, bias=False)\n","        (proj_v): Linear(in_features=128, out_features=128, bias=False)\n","        (proj_q): Linear(in_features=128, out_features=128, bias=False)\n","        (proj_out): Linear(in_features=128, out_features=128, bias=False)\n","        (dropout_layer): Dropout(p=0.1, inplace=False)\n","      )\n","      (feed_forward_layer): FeedForward(\n","        (ffn): Sequential(\n","          (0): Linear(in_features=128, out_features=512, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=512, out_features=128, bias=True)\n","          (3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","      (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (2): TransformerBlock(\n","      (multi_head_attention_layer): InfiniMultiHeadAttention(\n","        (proj_k): Linear(in_features=128, out_features=128, bias=False)\n","        (proj_v): Linear(in_features=128, out_features=128, bias=False)\n","        (proj_q): Linear(in_features=128, out_features=128, bias=False)\n","        (proj_out): Linear(in_features=128, out_features=128, bias=False)\n","        (dropout_layer): Dropout(p=0.1, inplace=False)\n","      )\n","      (feed_forward_layer): FeedForward(\n","        (ffn): Sequential(\n","          (0): Linear(in_features=128, out_features=512, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=512, out_features=128, bias=True)\n","          (3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","      (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (3): TransformerBlock(\n","      (multi_head_attention_layer): InfiniMultiHeadAttention(\n","        (proj_k): Linear(in_features=128, out_features=128, bias=False)\n","        (proj_v): Linear(in_features=128, out_features=128, bias=False)\n","        (proj_q): Linear(in_features=128, out_features=128, bias=False)\n","        (proj_out): Linear(in_features=128, out_features=128, bias=False)\n","        (dropout_layer): Dropout(p=0.1, inplace=False)\n","      )\n","      (feed_forward_layer): FeedForward(\n","        (ffn): Sequential(\n","          (0): Linear(in_features=128, out_features=512, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=512, out_features=128, bias=True)\n","          (3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","      (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (language_model_out_linear_layer): Linear(in_features=128, out_features=100278, bias=True)\n",")\n"]}],"source":["model = TransformerLanguageModel(\n","    dim_input=dim_input,\n","    num_heads=num_heads,\n","    num_blocks=num_blocks,\n","    context_length=context_length,\n","    max_token_value=max_token_value,\n","    dropout=dropout,\n","    infini=infni,\n","    segment_len=segment_len,\n",")\n","\n","\n","model = model.to(device)\n","\n","\n","print(model)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1719373622337,"user":{"displayName":"Matheus Rodrigues","userId":"10209371041900019376"},"user_tz":180},"id":"9NC_eAl7pJ0a"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":261},"id":"zA3mwLKVRz9w"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c05d126117d74dd8a6222466216e45d2","version_major":2,"version_minor":0},"text/plain":["Epochs:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"749acefa28274302ba5f5eb3f8bd9254","version_major":2,"version_minor":0},"text/plain":["Training Steps:   0%|          | 0/4952 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Step:      0 | Training Loss: 11.664 | Validation Loss: 11.670 | Training Perplexity: 116332.261 | Validation Perplexity: 117016.203\n","Step:    495 | Training Loss: 7.409 | Validation Loss: 7.434 | Training Perplexity: 1650.952 | Validation Perplexity: 1692.064\n","Step:    990 | Training Loss: 6.925 | Validation Loss: 6.958 | Training Perplexity: 1017.872 | Validation Perplexity: 1051.694\n","Step:   1485 | Training Loss: 6.372 | Validation Loss: 6.411 | Training Perplexity: 585.007 | Validation Perplexity: 608.333\n","Step:   1980 | Training Loss: 6.002 | Validation Loss: 6.048 | Training Perplexity: 404.057 | Validation Perplexity: 423.203\n","Step:   2475 | Training Loss: 5.742 | Validation Loss: 5.793 | Training Perplexity: 311.672 | Validation Perplexity: 328.153\n","Step:   2970 | Training Loss: 5.555 | Validation Loss: 5.611 | Training Perplexity: 258.600 | Validation Perplexity: 273.372\n","Step:   3465 | Training Loss: 5.419 | Validation Loss: 5.476 | Training Perplexity: 225.697 | Validation Perplexity: 238.937\n","Step:   3960 | Training Loss: 5.313 | Validation Loss: 5.373 | Training Perplexity: 203.032 | Validation Perplexity: 215.468\n","Step:   4455 | Training Loss: 5.231 | Validation Loss: 5.293 | Training Perplexity: 187.006 | Validation Perplexity: 198.942\n","Step:   4950 | Training Loss: 5.160 | Validation Loss: 5.223 | Training Perplexity: 174.166 | Validation Perplexity: 185.498\n","Step:   4951 | Training Loss: 5.159 | Validation Loss: 5.222 | Training Perplexity: 173.967 | Validation Perplexity: 185.261\n"]}],"source":["from tqdm.notebook import tqdm\n","\n","\n","# get num of trainable parameters model\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","def estimate_loss():\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","        out = {}\n","        losses = [0 for i in range(eval_iters)]\n","        steps = 0\n","        for batch in train_loader:\n","            if steps == eval_iters:\n","                break\n","            x_batch = batch[\"input_ids\"].to(device)\n","            y_batch = batch[\"labels\"].to(device)\n","\n","            # x_batch = x_batch\n","            # y_batch = y_batch\n","\n","            logits, loss = model(x_batch, targets=y_batch)\n","\n","            losses[steps] = loss.item()\n","            steps += 1\n","        out[\"train\"] = sum(losses) / eval_iters\n","\n","        losses = [0 for i in range(eval_iters)]\n","        steps = 0\n","        for batch in val_loader:\n","            if steps == eval_iters:\n","                break\n","            x_batch = batch[\"input_ids\"].to(device)\n","            y_batch = batch[\"labels\"].to(device)\n","\n","            # x_batch = x_batch\n","            # y_batch = y_batch\n","\n","            logits, loss = model(x_batch, targets=y_batch)\n","\n","            losses[steps] = loss.item()\n","            steps += 1\n","\n","        out[\"valid\"] = sum(losses) / eval_iters\n","\n","    model.train()\n","    return out\n","\n","\n","epochs = 1\n","max_iters = len(train_loader) * epochs\n","eval_interval = max_iters // 10  # Number of steps between evaluations\n","eval_iters = 20  # Number of iterations to average for evaluation\n","\n","# Use AdamW optimizer\n","optimizer = torch.optim.AdamW(params=model.parameters(), lr=learning_rate)\n","# SGD\n","# optimizer = torch.optim.SGD(params=model.parameters(), lr=learning_rate)\n","tracked_losses = list()\n","for epoch in tqdm(range(epochs), total=epochs, desc=\"Epochs\", leave=False):\n","    step = 0\n","    for batch in tqdm(\n","        train_loader, total=len(train_loader), desc=\"Training Steps\", leave=False\n","    ):\n","        optimizer.zero_grad()\n","\n","        # print gpu consumed\n","        # print(f'total GPU usage:{torch.cuda.memory_allocated()/1024**3:.2f} GB')\n","        if step % eval_interval == 0 or step == max_iters - 1:\n","            losses = estimate_loss()\n","            tracked_losses.append(losses)\n","            # print(losses)\n","            print(\n","                f\"Step: {step:>6} | \"\n","                f\"Training Loss: {losses['train']:.3f} | \"\n","                f\"Validation Loss: {losses['valid']:.3f} | \"\n","                f\"Training Perplexity: {math.exp(losses['train']):.3f} | \"\n","                f\"Validation Perplexity: {math.exp(losses['valid']):.3f}\"\n","            )\n","\n","        x_batch = batch[\"input_ids\"].to(device)\n","        y_batch = batch[\"labels\"].to(device)\n","        logits, loss = model(x_batch, y_batch)\n","        loss.backward()\n","        optimizer.step()\n","        step += 1\n","\n","\n","# Save the model state dictionary\n","os.makedirs(\"ckpt\", exist_ok=True)\n","torch.save(model.state_dict(), \"ckpt/model-infini-4096-64.pt\")\n","# write tracked_losses\n","with open(\"ckpt/tracked_losses.txt\", \"w\") as f:\n","    f.write(str(tracked_losses))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fbGI1LqSpdyr"},"outputs":[],"source":["import time\n","\n","time.sleep(10)\n","\n","from google.colab import runtime\n","\n","runtime.unassign()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oE9USgT7Rz9w"},"outputs":[],"source":["# # Generate\n","# model.eval()\n","# # start = ''\n","# # start_ids = encoding.encode(start)\n","# idx = 4\n","# start_ids = test_data[idx * context_length : (idx + 1) * context_length]\n","# x = torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...]\n","# # print(x.shape)\n","# y = model.generate(x, max_new_tokens=int(10))\n","# print(\"------original text---------\")\n","# print(encoding.decode(start_ids.tolist()))\n","# print(\"------only new tokens-------\")\n","# print(encoding.decode(y[0][len(start_ids) :].tolist()))\n","# print(\"----------------------------\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_LkTvVzng_Wx"},"outputs":[],"source":["# # prompt: Plot the train and validation loss stored in tracked_losses\n","\n","# import matplotlib.pyplot as plt\n","\n","# # Extract train and validation losses from tracked_losses\n","# train_losses = [loss[\"train\"].cpu() for loss in tracked_losses]\n","# val_losses = [loss[\"valid\"].cpu() for loss in tracked_losses]\n","\n","# # Create the plot\n","# plt.plot(\n","#     list(range(0, eval_interval * len(train_losses), eval_interval)),\n","#     train_losses,\n","#     label=\"Train Loss\",\n","# )\n","# plt.plot(\n","#     list(range(0, eval_interval * len(train_losses), eval_interval)),\n","#     val_losses,\n","#     label=\"Validation Loss\",\n","# )\n","\n","# # Add labels and title\n","# plt.xlabel(\"Step\")\n","# plt.ylabel(\"Loss\")\n","# plt.title(\"Train and Validation Loss over Iterations\")\n","\n","# # Add legend and show the plot\n","# plt.legend()\n","# plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"19355b142c8a42ac872890ce8d7bc1a4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4174d3f916f14df38d54dff818b93043":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49c85e05d4d7447cb4b51c9714493ee4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c45b0d50bb1489ca6d987fe3f4223ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51ff1d6018b346319945aa3d74d3bc07":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68067b50db7d42ec8762894365252fd4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"733b3ba280c442ff90b57a862dd1faa8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4174d3f916f14df38d54dff818b93043","placeholder":"​","style":"IPY_MODEL_51ff1d6018b346319945aa3d74d3bc07","value":"Training Steps:  91%"}},"749acefa28274302ba5f5eb3f8bd9254":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_733b3ba280c442ff90b57a862dd1faa8","IPY_MODEL_bed9289d81364202ac364556c03c9870","IPY_MODEL_f6899daa285b41e5a0e2ed9aaead25fc"],"layout":"IPY_MODEL_49c85e05d4d7447cb4b51c9714493ee4"}},"795dbf6f9a2c4feb87d906447f5ce6ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a9bc317401964b16b266afb60a7f07a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abf1eec1a5bf4eec9040d11f7efb5d56":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6398289286946aaaee643e6d636ce7e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e314a6c2ff384053b31ba32738f5cb49","value":0}},"bed9289d81364202ac364556c03c9870":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9bc317401964b16b266afb60a7f07a5","max":4952,"min":0,"orientation":"horizontal","style":"IPY_MODEL_795dbf6f9a2c4feb87d906447f5ce6ed","value":4483}},"c05d126117d74dd8a6222466216e45d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cdda6621fea04c23b94bb393cf584161","IPY_MODEL_abf1eec1a5bf4eec9040d11f7efb5d56","IPY_MODEL_fdbb264c0bd144878e1ff598d7f54d79"],"layout":"IPY_MODEL_4c45b0d50bb1489ca6d987fe3f4223ad"}},"cdda6621fea04c23b94bb393cf584161":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68067b50db7d42ec8762894365252fd4","placeholder":"​","style":"IPY_MODEL_fad96b782b8640a19f79d71dfe5fa049","value":"Epochs:   0%"}},"e314a6c2ff384053b31ba32738f5cb49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e6398289286946aaaee643e6d636ce7e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f32fdf451a614a698012c40cd35db9c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f6899daa285b41e5a0e2ed9aaead25fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa47e554642f454cbf6010e4bdcc1682","placeholder":"​","style":"IPY_MODEL_f32fdf451a614a698012c40cd35db9c0","value":" 4483/4952 [20:37&lt;02:03,  3.80it/s]"}},"fa47e554642f454cbf6010e4bdcc1682":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fad96b782b8640a19f79d71dfe5fa049":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fdbb264c0bd144878e1ff598d7f54d79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19355b142c8a42ac872890ce8d7bc1a4","placeholder":"​","style":"IPY_MODEL_ff7eb82bd6ba4cc9998b6cedc9da90a0","value":" 0/1 [00:00&lt;?, ?it/s]"}},"ff7eb82bd6ba4cc9998b6cedc9da90a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
